package main

import (
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"strconv"
	"strings"
	"time"
	gounicode "unicode"

	"github.com/blevesearch/bleve/v2"
	"github.com/blevesearch/bleve/v2/analysis/analyzer/custom"
	_ "github.com/blevesearch/bleve/v2/analysis/char/html"
	_ "github.com/blevesearch/bleve/v2/analysis/lang/cjk"
	"github.com/blevesearch/bleve/v2/analysis/token/edgengram"
	"github.com/blevesearch/bleve/v2/analysis/token/lowercase"
	_ "github.com/blevesearch/bleve/v2/analysis/token/ngram"
	"github.com/blevesearch/bleve/v2/analysis/token/unicodenorm"
	"github.com/blevesearch/bleve/v2/analysis/tokenizer/unicode"
	_ "github.com/blevesearch/bleve/v2/index/upsidedown/store/boltdb"
	"github.com/blevesearch/bleve/v2/search/highlight/format/html"
	"github.com/blevesearch/bleve/v2/search/query"

	_ "github.com/go-sql-driver/mysql"
	"github.com/joho/godotenv"
)

// MarkerDB represents the structure of the marker data from DB.
type MarkerDB struct {
	MarkerID int    `json:"markerId"`
	Address  string `json:"address"`
}

type Marker struct {
	MarkerID          int    `json:"markerId"`
	Province          string `json:"province"`
	City              string `json:"city"`
	Address           string `json:"address"` // such as Korean: Í≤ΩÍ∏∞ÎèÑ Î∂ÄÏ≤úÏãú ÏÜåÏÇ¨Íµ¨ Í≤ΩÏù∏Î°ú29Î≤àÍ∏∏ 32, Ïö∞ÏÑ±ÏïÑÌååÌä∏
	FullAddress       string `json:"fullAddress"`
	InitialConsonants string `json:"initialConsonants"` // Ï¥àÏÑ±
}

// Load environment variables from .env file
func loadEnv() error {
	err := godotenv.Load()
	if err != nil {
		return fmt.Errorf("error loading .env file: %v", err)
	}
	return nil
}

func saveJson() error {
	// Database connection parameters
	dbHost := os.Getenv("DB_HOST")
	dbUser := os.Getenv("DB_USERNAME")
	dbPassword := os.Getenv("DB_PASSWORD")
	dbName := os.Getenv("DB_NAME")

	// Database connection string
	dsn := fmt.Sprintf("%s:%s@tcp(%s)/%s?charset=utf8mb4&parseTime=True&loc=Local", dbUser, dbPassword, dbHost, dbName)

	// Open database connection
	db, err := sql.Open("mysql", dsn)
	if err != nil {
		return fmt.Errorf("error connecting to the database: %v", err)
	}
	defer db.Close()

	// Query to select all rows from the Markers table
	selectSQL := `SELECT MarkerID, Address FROM Markers`

	// Execute the query
	rows, err := db.Query(selectSQL)
	if err != nil {
		return fmt.Errorf("error executing query: %v", err)
	}
	defer rows.Close()

	// Prepare data for JSON
	var markers []MarkerDB
	for rows.Next() {
		var marker MarkerDB
		err := rows.Scan(&marker.MarkerID, &marker.Address)
		if err != nil {
			return fmt.Errorf("error scanning row: %v", err)
		}
		markers = append(markers, marker)
	}

	// Check for errors from iterating over rows
	if err := rows.Err(); err != nil {
		return fmt.Errorf("error iterating over rows: %v", err)
	}

	// Write to JSON file
	file, err := os.Create("markers.json")
	if err != nil {
		return fmt.Errorf("error creating JSON file: %v", err)
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	encoder.SetIndent("", "  ")
	err = encoder.Encode(markers)
	if err != nil {
		return fmt.Errorf("error encoding JSON: %v", err)
	}

	fmt.Println("Data has been written to markers.json")

	return nil
}

func main() {
	// Load environment variables
	err := loadEnv()
	if err != nil {
		log.Fatalf("Error loading .env file: %v", err)
	}

	if len(os.Args) < 2 {
		saveJson()
		log.Println("Fetching completed.")
	}

	// Sample JSON data
	markers, _ := getMarkersFromJson("markers.json")

	// Create a new Bleve index
	// Define index path
	indexPath := "markers.bleve"

	// Define custom mapping
	indexMapping := bleve.NewIndexMapping()
	err = indexMapping.AddCustomTokenFilter("edge_ngram_min_1_max_4",
		map[string]interface{}{
			"type": edgengram.Name,
			"min":  1.0,
			"max":  4.0,
		})
	if err != nil {
		log.Fatalf("Error creating custom analyzer: %v", err)
	}

	err = indexMapping.AddCustomTokenFilter("unicodeNormalizer",
		map[string]interface{}{
			"type": unicodenorm.Name,
			"form": unicodenorm.NFKC,
		})
	if err != nil {
		log.Fatalf("Error creating custom token filter: %v", err)
	}

	// normalize -> CJK bigrams -> edge ngrams -> lowercase
	err = indexMapping.AddCustomAnalyzer("koCJKEdgeNgram",
		map[string]interface{}{
			"type":         custom.Name,
			"tokenizer":    unicode.Name,
			"char_filters": []string{html.Name},
			"token_filters": []string{
				"unicodeNormalizer",
				"cjk_bigram",
				"edge_ngram_min_1_max_4",
				lowercase.Name,
			},
		})
	if err != nil {

		log.Fatalf("Error creating custom analyzer: %v", err)
	}

	markerMapping := bleve.NewDocumentMapping()

	markerIDMapping := bleve.NewNumericFieldMapping()
	markerMapping.AddFieldMappingsAt("markerId", markerIDMapping)

	provinceMapping := bleve.NewTextFieldMapping()
	provinceMapping.Analyzer = "koCJKEdgeNgram"
	provinceMapping.Store = true
	provinceMapping.IncludeTermVectors = true
	markerMapping.AddFieldMappingsAt("province", provinceMapping)

	cityMapping := bleve.NewTextFieldMapping()
	cityMapping.Analyzer = "koCJKEdgeNgram"
	cityMapping.Store = true
	cityMapping.IncludeTermVectors = true
	markerMapping.AddFieldMappingsAt("city", cityMapping)

	addressMapping := bleve.NewTextFieldMapping()
	addressMapping.Analyzer = "koCJKEdgeNgram"
	addressMapping.Store = true
	addressMapping.IncludeTermVectors = true
	markerMapping.AddFieldMappingsAt("address", addressMapping)

	fullAddressMapping := bleve.NewTextFieldMapping()
	fullAddressMapping.Store = true
	fullAddressMapping.IncludeTermVectors = true
	markerMapping.AddFieldMappingsAt("fullAddress", fullAddressMapping)

	initialConsonantsMapping := bleve.NewTextFieldMapping()
	initialConsonantsMapping.Analyzer = "koCJKEdgeNgram"
	initialConsonantsMapping.Store = true
	initialConsonantsMapping.IncludeTermVectors = true
	markerMapping.AddFieldMappingsAt("initialConsonants", initialConsonantsMapping)

	indexMapping.AddDocumentMapping("marker", markerMapping)

	// Create a new Bleve index with custom settings
	index, err := bleve.New(indexPath, indexMapping)
	if err != nil {
		if len(os.Args) < 2 {
			search("ÏòÅÌÜµÏó≠")
		} else {
			searchTerm := strings.Join(os.Args[1:], " ")
			search(searchTerm)
		}

		log.Fatalf("Error creating index: %v", err)
	}

	// Index the markers
	for i, marker := range markers {
		province, city, rest := splitAddress(marker.Address)
		marker.Province = province
		marker.City = city
		marker.FullAddress = marker.Address
		marker.Address = rest
		marker.InitialConsonants = extractInitialConsonants(marker.FullAddress)
		if i == 10 {
			log.Printf("üåç address: %s (%s)", marker.FullAddress, marker.InitialConsonants)
		}
		err = index.Index(strconv.Itoa(marker.MarkerID), marker)
		if err != nil {
			log.Fatalf("Error indexing document: %v", err)
		}
	}

	log.Println("Indexing completed")

	index.Close()

	// Perform a search using DisjunctionQuery for more comprehensive matching
	search("Ìï¥Ïö¥ÎåÄ")

}

func search(t string) {
	index, _ := bleve.Open("markers.bleve")
	defer index.Close()

	// index.Index("test", Marker{Address: "ÏÑùÏõê", MarkerID: 123, FullAddress: "Í≤ΩÍ∏∞ÎèÑ ÏÑùÏõêÎèô 123-456"})
	// index.Delete("test")

	// Capture the start time
	start := time.Now()

	// Split the search term by spaces
	terms := strings.Fields(t)
	var queries []query.Query

	// Add a phrase query for the full search term
	// phraseQuery := query.NewMatchPhraseQuery(t)
	// phraseQuery.SetBoost(3.0)
	// phraseQuery.Analyzer = "koCJKEdgeNgram"
	// queries = append(queries, phraseQuery)

	for _, term := range terms {
		// Add a MatchQuery for the full search term
		matchQuery := query.NewMatchQuery(term)
		matchQuery.SetField("initialConsonants")
		matchQuery.Analyzer = "koCJKEdgeNgram"
		matchQuery.SetBoost(10.0)
		queries = append(queries, matchQuery)

		// Use WildcardQuery for more flexible matches
		wildcardQuery := query.NewWildcardQuery("*" + term + "*")
		wildcardQuery.SetField("initialConsonants")
		wildcardQuery.SetBoost(5.0)
		queries = append(queries, wildcardQuery)

		standardizedProvince := standardizeProvince(term)
		if standardizedProvince != term {
			// If the term is a province, use a lower boost
			matchQuery := query.NewMatchQuery(standardizedProvince)
			matchQuery.SetField("province")
			matchQuery.Analyzer = "koCJKEdgeNgram"
			matchQuery.SetBoost(1.5)
			queries = append(queries, matchQuery)
		} else {
			// Use PrefixQuery for cities and regions
			prefixQueryCity := query.NewPrefixQuery(term)
			prefixQueryCity.SetField("city")
			prefixQueryCity.SetBoost(10.0)
			queries = append(queries, prefixQueryCity)

			// Use MatchPhraseQuery for detailed matches in full address
			matchPhraseQueryFull := query.NewMatchPhraseQuery(term)
			matchPhraseQueryFull.SetField("fullAddress")
			matchPhraseQueryFull.Analyzer = "koCJKEdgeNgram"
			matchPhraseQueryFull.SetBoost(5.0)
			queries = append(queries, matchPhraseQueryFull)

			// Use WildcardQuery for more flexible matches
			wildcardQueryFull := query.NewWildcardQuery("*" + term + "*")
			wildcardQueryFull.SetField("fullAddress")
			wildcardQueryFull.SetBoost(2.0)
			queries = append(queries, wildcardQueryFull)

			// Additional PrefixQuery and WildcardQuery for other fields
			prefixQueryAddr := query.NewPrefixQuery(term)
			prefixQueryAddr.SetField("address")
			prefixQueryAddr.SetBoost(5.0)
			queries = append(queries, prefixQueryAddr)

			wildcardQueryAddr := query.NewWildcardQuery("*" + term + "*")
			wildcardQueryAddr.SetField("address")
			wildcardQueryAddr.SetBoost(2.0)
			queries = append(queries, wildcardQueryAddr)

			// Use MatchQuery for city and district to catch all matches
			matchQueryCity := query.NewMatchQuery(term)
			matchQueryCity.SetField("city")
			matchQueryCity.Analyzer = "koCJKEdgeNgram"
			matchQueryCity.SetBoost(5.0)
			queries = append(queries, matchQueryCity)

			matchQueryDistrict := query.NewMatchQuery(term)
			matchQueryDistrict.SetField("district")
			matchQueryDistrict.Analyzer = "koCJKEdgeNgram"
			matchQueryDistrict.SetBoost(5.0)
			queries = append(queries, matchQueryDistrict)
		}
	}

	disjunctionQuery := bleve.NewDisjunctionQuery(queries...)
	// conjunctionQuery := bleve.NewConjunctionQuery(disjunctionQuery)

	searchRequest := bleve.NewSearchRequest(disjunctionQuery)
	searchRequest.Fields = []string{"fullAddress", "address", "province", "city", "initialConsonants"}
	searchRequest.Size = 10 // Limit the number of results
	searchResult, err := index.Search(searchRequest)
	searchRequest.SortBy([]string{"_score", "markerId"})
	if err != nil {
		log.Fatalf("Error performing search: %v", err)
	}

	if len(searchResult.Hits) > 0 {
		for _, hit := range searchResult.Hits {
			log.Printf("Search Result: %+v", hit)
			log.Printf("Document ID: %v", hit.ID)
			log.Printf("Document Score: %v", hit.Score)
			if fullAddress, ok := hit.Fields["fullAddress"]; ok {
				log.Printf("Full Address: %v", fullAddress)
			}
			// if province, ok := hit.Fields["province"]; ok {
			// 	log.Printf("Province: %v", province)
			// }
			// if city, ok := hit.Fields["city"]; ok {
			// 	log.Printf("City: %v", city)
			// }
			// if address, ok := hit.Fields["address"]; ok {
			// 	log.Printf("Address: %v", address)
			// }
		}
	} else {
		log.Println("No search results found")
	}

	if len(searchResult.Hits) > 0 {
		for _, hit := range searchResult.Hits {
			log.Printf("Search Result: %+v", hit)
			log.Printf("Document ID: %v", hit.ID)
			log.Printf("Document Score: %v", hit.Score)
			if fullAddress, ok := hit.Fields["fullAddress"]; ok {
				log.Printf("Full Address: %v", fullAddress)
			}
		}
	} else {
		log.Println("No search results found")

		// If no results, try fuzzy search with controlled fuzziness
		for _, term := range terms {
			fuzzyQuery := bleve.NewFuzzyQuery(term)
			fuzzyQuery.Fuzziness = 1
			searchRequest = bleve.NewSearchRequest(fuzzyQuery)
			searchRequest.Fields = []string{"fullAddress", "address", "province", "city"}
			searchRequest.Size = 10
			searchResult, err = index.Search(searchRequest)
			if err != nil {
				log.Fatalf("Error performing fuzzy search: %v", err)
			}
			if len(searchResult.Hits) > 0 {
				for _, hit := range searchResult.Hits {
					log.Printf("Search Result: %+v", hit)
					log.Printf("Document ID: %v", hit.ID)
					log.Printf("Document Score: %v", hit.Score)
					if fullAddress, ok := hit.Fields["fullAddress"]; ok {
						log.Printf("Full Address: %v", fullAddress)
					}
				}
			}
		}
	}

	// Capture the end time
	end := time.Now()
	// Calculate the duration
	duration := end.Sub(start)

	// Log the duration
	log.Printf("üìÜFunction runtime: %v", duration)
}

func standardizeProvince(province string) string {
	switch province {
	case "Í≤ΩÍ∏∞", "Í≤ΩÍ∏∞ÎèÑ":
		return "Í≤ΩÍ∏∞ÎèÑ"
	case "ÏÑúÏö∏", "ÏÑúÏö∏ÌäπÎ≥ÑÏãú":
		return "ÏÑúÏö∏ÌäπÎ≥ÑÏãú"
	case "Î∂ÄÏÇ∞", "Î∂ÄÏÇ∞Í¥ëÏó≠Ïãú":
		return "Î∂ÄÏÇ∞Í¥ëÏó≠Ïãú"
	case "ÎåÄÍµ¨", "ÎåÄÍµ¨Í¥ëÏó≠Ïãú":
		return "ÎåÄÍµ¨Í¥ëÏó≠Ïãú"
	case "Ïù∏Ï≤ú", "Ïù∏Ï≤úÍ¥ëÏó≠Ïãú":
		return "Ïù∏Ï≤úÍ¥ëÏó≠Ïãú"
	case "Ï†úÏ£º", "Ï†úÏ£ºÌäπÎ≥ÑÏûêÏπòÎèÑ", "Ï†úÏ£ºÎèÑ":
		return "Ï†úÏ£ºÌäπÎ≥ÑÏûêÏπòÎèÑ"
	case "ÎåÄÏ†Ñ", "ÎåÄÏ†ÑÍ¥ëÏó≠Ïãú":
		return "ÎåÄÏ†ÑÍ¥ëÏó≠Ïãú"
	case "Ïö∏ÏÇ∞", "Ïö∏ÏÇ∞Í¥ëÏó≠Ïãú":
		return "Ïö∏ÏÇ∞Í¥ëÏó≠Ïãú"
	case "Í¥ëÏ£º", "Í¥ëÏ£ºÍ¥ëÏó≠Ïãú":
		return "Í¥ëÏ£ºÍ¥ëÏó≠Ïãú"
	case "ÏÑ∏Ï¢Ö", "ÏÑ∏Ï¢ÖÌäπÎ≥ÑÏûêÏπòÏãú":
		return "ÏÑ∏Ï¢ÖÌäπÎ≥ÑÏûêÏπòÏãú"
	case "Í∞ïÏõê", "Í∞ïÏõêÎèÑ", "Í∞ïÏõêÌäπÎ≥ÑÏûêÏπòÎèÑ":
		return "Í∞ïÏõêÌäπÎ≥ÑÏûêÏπòÎèÑ"
	case "Í≤ΩÎÇ®", "Í≤ΩÏÉÅÎÇ®ÎèÑ":
		return "Í≤ΩÏÉÅÎÇ®ÎèÑ"
	case "Í≤ΩÎ∂Å", "Í≤ΩÏÉÅÎ∂ÅÎèÑ":
		return "Í≤ΩÏÉÅÎ∂ÅÎèÑ"
	case "Ï†ÑÎ∂Å", "Ï†ÑÎ∂ÅÌäπÎ≥ÑÏûêÏπòÎèÑ":
		return "Ï†ÑÎ∂ÅÌäπÎ≥ÑÏûêÏπòÎèÑ"
	case "Ï∂©ÎÇ®", "Ï∂©Ï≤≠ÎÇ®ÎèÑ":
		return "Ï∂©Ï≤≠ÎÇ®ÎèÑ"
	case "Ï∂©Î∂Å", "Ï∂©Ï≤≠Î∂ÅÎèÑ":
		return "Ï∂©Ï≤≠Î∂ÅÎèÑ"
	case "Ï†ÑÎÇ®", "Ï†ÑÎùºÎÇ®ÎèÑ":
		return "Ï†ÑÎùºÎÇ®ÎèÑ"
	default:
		return province
	}
}

func splitAddress(address string) (string, string, string) {
	parts := strings.Fields(address)
	if len(parts) < 2 {
		return "", "", address
	}
	province := standardizeProvince(parts[0])
	city := parts[1]
	rest := strings.Join(parts[2:], " ")
	return province, city, rest
}

func getMarkersFromJson(filepath string) ([]Marker, error) {
	var markerData []Marker

	file, err := os.Open(filepath)
	if err != nil {
		return markerData, err
	}
	defer file.Close()

	decoder := json.NewDecoder(file)
	err = decoder.Decode(&markerData)
	if err != nil {
		return markerData, err
	}

	return markerData, nil
}

// Map of Hangul initial consonant Unicode values to their corresponding Korean consonants.
var initialConsonantMap = map[rune]rune{
	0x1100: '„Ñ±', 0x1101: '„Ñ≤', 0x1102: '„Ñ¥', 0x1103: '„Ñ∑', 0x1104: '„Ñ∏',
	0x1105: '„Ñπ', 0x1106: '„ÖÅ', 0x1107: '„ÖÇ', 0x1108: '„ÖÉ', 0x1109: '„ÖÖ',
	0x110A: '„ÖÜ', 0x110B: '„Öá', 0x110C: '„Öà', 0x110D: '„Öâ', 0x110E: '„Öä',
	0x110F: '„Öã', 0x1110: '„Öå', 0x1111: '„Öç', 0x1112: '„Öé',
}

// ExtractInitialConsonants extracts the initial consonants from a Korean string.
// ex) "Î∂ÄÏÇ∞ Ìï¥Ïö¥ÎåÄÍµ¨ Ï¢åÎèô 1395" -> "„ÖÇ„ÖÖ„Öé„Öá„Ñ∑„Ñ±„Öà„Ñ∑"
func extractInitialConsonants(s string) string {
	var initials []rune
	for _, r := range s {
		if gounicode.Is(gounicode.Hangul, r) {
			initial := (r - 0xAC00) / 28 / 21
			if mapped, exists := initialConsonantMap[0x1100+initial]; exists {
				initials = append(initials, mapped)
			}
		}
	}
	return string(initials)
}

/*
my json looks like

[
  {
    "markerId": 1,
    "address": "Í≤ΩÎ∂Å Ìè¨Ìï≠Ïãú Î∂ÅÍµ¨ Ï∞ΩÌè¨Îèô 655"
  },
  {
    "markerId": 2,
    "address": "ÏÑúÏö∏ ÎÖ∏ÏõêÍµ¨ ÌïòÍ≥ÑÎèô 250"
  },
]
*/
